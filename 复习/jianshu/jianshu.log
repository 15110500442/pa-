2018-06-24 20:22:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-24 20:22:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-24 20:22:01 [scrapy.crawler] INFO: Overridden settings: {'SPIDER_MODULES': ['jianshu.spiders'], 'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_FILE': 'jianshu.log', 'BOT_NAME': 'jianshu', 'LOG_LEVEL': 'INFO'}
2018-06-24 20:22:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-24 20:22:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-24 20:22:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-24 20:22:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-24 20:22:01 [scrapy.core.engine] INFO: Spider opened
2018-06-24 20:22:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-24 20:34:52 [scrapy.crawler] INFO: Received SIGTERM, shutting down gracefully. Send again to force 
2018-06-25 09:17:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 09:17:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 09:17:42 [scrapy.crawler] INFO: Overridden settings: {'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_FILE': 'jianshu.log', 'BOT_NAME': 'jianshu', 'SPIDER_MODULES': ['jianshu.spiders']}
2018-06-25 09:17:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 09:17:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 09:17:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 09:17:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 09:17:43 [scrapy.core.engine] INFO: Spider opened
2018-06-25 09:17:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 10:09:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 10:09:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 10:09:17 [scrapy.crawler] INFO: Overridden settings: {'LOG_FILE': 'jianshu.log', 'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_LEVEL': 'INFO', 'SPIDER_MODULES': ['jianshu.spiders'], 'BOT_NAME': 'jianshu'}
2018-06-25 10:09:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2018-06-25 10:09:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['jianshu.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'jianshu.middlewares.JianshuDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 10:09:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 10:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 10:09:17 [scrapy.core.engine] INFO: Spider opened
2018-06-25 10:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 10:09:17 [jians] INFO: Spider opened: jians
2018-06-25 10:20:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 10:20:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 10:20:20 [scrapy.crawler] INFO: Overridden settings: {'LOG_FILE': 'jianshu.log', 'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'jianshu', 'USER_AGENT': {'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.17 Safari/537.36Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2309.372 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.14 (KHTML, like Gecko) Chrome/24.0.1292.0 Safari/537.14'}, 'SPIDER_MODULES': ['jianshu.spiders']}
2018-06-25 10:20:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-06-25 10:20:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['jianshu.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'jianshu.middlewares.JianshuDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 10:20:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 10:20:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 10:20:20 [scrapy.core.engine] INFO: Spider opened
2018-06-25 10:20:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 10:20:20 [jians] INFO: Spider opened: jians
2018-06-25 10:20:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.jianshu.com>
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "/home/bc/桌面/pachong/jianshu/jianshu/middlewares.py", line 122, in process_request
    usersgent = random.choice(self.UserAgent)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/random.py", line 256, in choice
    return seq[i]
TypeError: 'set' object does not support indexing
2018-06-25 10:20:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-06-25 10:20:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.TypeError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 6, 25, 2, 20, 20, 627438),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 52596736,
 'memusage/startup': 52596736,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 6, 25, 2, 20, 20, 328485)}
2018-06-25 10:20:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-06-25 10:21:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 10:21:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 10:21:03 [scrapy.crawler] INFO: Overridden settings: {'LOG_FILE': 'jianshu.log', 'LOG_LEVEL': 'INFO', 'USER_AGENT': {'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.17 Safari/537.36Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2309.372 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.14 (KHTML, like Gecko) Chrome/24.0.1292.0 Safari/537.14'}, 'SPIDER_MODULES': ['jianshu.spiders'], 'BOT_NAME': 'jianshu', 'NEWSPIDER_MODULE': 'jianshu.spiders'}
2018-06-25 10:21:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 10:21:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['jianshu.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'jianshu.middlewares.JianshuDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 10:21:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 10:21:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 10:21:03 [scrapy.core.engine] INFO: Spider opened
2018-06-25 10:21:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 10:21:03 [jians] INFO: Spider opened: jians
2018-06-25 10:21:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.jianshu.com>
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "/home/bc/桌面/pachong/jianshu/jianshu/middlewares.py", line 122, in process_request
    usersgent = random.choice(self.UserAgent)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/random.py", line 256, in choice
    return seq[i]
TypeError: 'set' object does not support indexing
2018-06-25 10:21:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-06-25 10:21:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.TypeError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 6, 25, 2, 21, 3, 741950),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 52625408,
 'memusage/startup': 52625408,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 6, 25, 2, 21, 3, 528723)}
2018-06-25 10:21:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-06-25 10:21:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 10:21:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 10:21:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jianshu', 'LOG_LEVEL': 'INFO', 'SPIDER_MODULES': ['jianshu.spiders'], 'USER_AGENT': {'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.17 Safari/537.36Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2309.372 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.14 (KHTML, like Gecko) Chrome/24.0.1292.0 Safari/537.14'}, 'LOG_FILE': 'jianshu.log', 'NEWSPIDER_MODULE': 'jianshu.spiders'}
2018-06-25 10:21:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-06-25 10:21:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['jianshu.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'jianshu.middlewares.JianshuDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 10:21:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 10:21:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 10:21:42 [scrapy.core.engine] INFO: Spider opened
2018-06-25 10:21:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 10:21:42 [jians] INFO: Spider opened: jians
2018-06-25 10:21:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.jianshu.com>
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "/home/bc/桌面/pachong/jianshu/jianshu/middlewares.py", line 122, in process_request
    useragent = random.choice(self.UserAgent)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/random.py", line 256, in choice
    return seq[i]
TypeError: 'set' object does not support indexing
2018-06-25 10:21:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-06-25 10:21:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.TypeError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 6, 25, 2, 21, 42, 498143),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 52715520,
 'memusage/startup': 52715520,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 6, 25, 2, 21, 42, 285014)}
2018-06-25 10:21:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-06-25 11:11:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:11:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:11:01 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': {'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.17 Safari/537.36Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2309.372 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.14 (KHTML, like Gecko) Chrome/24.0.1292.0 Safari/537.14'}, 'LOG_FILE': 'jianshu.log', 'LOG_LEVEL': 'INFO', 'SPIDER_MODULES': ['jianshu.spiders'], 'NEWSPIDER_MODULE': 'jianshu.spiders', 'BOT_NAME': 'jianshu'}
2018-06-25 11:11:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-06-25 11:11:01 [twisted] CRITICAL: Unhandled error in Deferred:
2018-06-25 11:11:01 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'jianshu.middlewares' has no attribute 'RandomUserAgentMiddleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'jianshu.middlewares' doesn't define any object named 'RandomUserAgentMiddleware'
2018-06-25 11:13:19 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:13:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:13:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jianshu', 'SPIDER_MODULES': ['jianshu.spiders'], 'LOG_FILE': 'jianshu.log', 'LOG_LEVEL': 'INFO', 'USER_AGENT': {'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.17 Safari/537.36Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2309.372 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.14 (KHTML, like Gecko) Chrome/24.0.1292.0 Safari/537.14'}, 'NEWSPIDER_MODULE': 'jianshu.spiders'}
2018-06-25 11:13:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2018-06-25 11:13:19 [twisted] CRITICAL: Unhandled error in Deferred:
2018-06-25 11:13:19 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'jianshu.middlewares' has no attribute 'RandomUserAgentMiddleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'jianshu.middlewares' doesn't define any object named 'RandomUserAgentMiddleware'
2018-06-25 11:13:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:13:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:13:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jianshu', 'LOG_FILE': 'jianshu.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'jianshu.spiders', 'SPIDER_MODULES': ['jianshu.spiders'], 'USER_AGENT': {'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.17 Safari/537.36Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2309.372 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.14 (KHTML, like Gecko) Chrome/24.0.1292.0 Safari/537.14'}}
2018-06-25 11:13:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-06-25 11:13:56 [twisted] CRITICAL: Unhandled error in Deferred:
2018-06-25 11:13:56 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'jianshu.middlewares' has no attribute 'RandomUserAgentMiddleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'jianshu.middlewares' doesn't define any object named 'RandomUserAgentMiddleware'
2018-06-25 11:15:36 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:15:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:15:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jianshu', 'LOG_LEVEL': 'INFO', 'SPIDER_MODULES': ['jianshu.spiders'], 'LOG_FILE': 'jianshu.log', 'NEWSPIDER_MODULE': 'jianshu.spiders'}
2018-06-25 11:15:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-06-25 11:15:36 [twisted] CRITICAL: Unhandled error in Deferred:
2018-06-25 11:15:36 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'jianshu.middlewares' has no attribute 'RandomUserAgentMiddleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'jianshu.middlewares' doesn't define any object named 'RandomUserAgentMiddleware'
2018-06-25 11:33:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:33:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:33:04 [scrapy.crawler] INFO: Overridden settings: {'LOG_LEVEL': 'INFO', 'BOT_NAME': 'jianshu', 'LOG_FILE': 'jianshu.log', 'NEWSPIDER_MODULE': 'jianshu.spiders', 'SPIDER_MODULES': ['jianshu.spiders']}
2018-06-25 11:33:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 11:33:04 [twisted] CRITICAL: Unhandled error in Deferred:
2018-06-25 11:33:04 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'jianshu.middlewares' has no attribute 'RandomUserAgentMiddleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'jianshu.middlewares' doesn't define any object named 'RandomUserAgentMiddleware'
2018-06-25 11:34:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:34:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:34:01 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_LEVEL': 'INFO', 'LOG_FILE': 'jianshu.log', 'SPIDER_MODULES': ['jianshu.spiders'], 'BOT_NAME': 'jianshu'}
2018-06-25 11:34:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2018-06-25 11:34:01 [twisted] CRITICAL: Unhandled error in Deferred:
2018-06-25 11:34:01 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'jianshu.middlewares' has no attribute 'RandomUserAgentMiddleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'jianshu.middlewares' doesn't define any object named 'RandomUserAgentMiddleware'
2018-06-25 11:34:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:34:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:34:20 [scrapy.crawler] INFO: Overridden settings: {'LOG_FILE': 'jianshu.log', 'BOT_NAME': 'jianshu', 'SPIDER_MODULES': ['jianshu.spiders'], 'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_LEVEL': 'INFO'}
2018-06-25 11:34:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-06-25 11:34:20 [twisted] CRITICAL: Unhandled error in Deferred:
2018-06-25 11:34:20 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'jianshu.middlewares' has no attribute 'RandomUserAgentMiddleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'jianshu.middlewares' doesn't define any object named 'RandomUserAgentMiddleware'
2018-06-25 11:36:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:36:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:36:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jianshu', 'SPIDER_MODULES': ['jianshu.spiders'], 'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_FILE': 'jianshu.log', 'LOG_LEVEL': 'INFO'}
2018-06-25 11:36:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 11:36:31 [twisted] CRITICAL: Unhandled error in Deferred:
2018-06-25 11:36:31 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'jianshu.middlewares' has no attribute 'RandomUserAgentMiddleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'jianshu.middlewares' doesn't define any object named 'RandomUserAgentMiddleware'
2018-06-25 11:36:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:36:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:36:51 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_FILE': 'jianshu.log', 'SPIDER_MODULES': ['jianshu.spiders'], 'BOT_NAME': 'jianshu', 'LOG_LEVEL': 'INFO'}
2018-06-25 11:36:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 11:36:51 [twisted] CRITICAL: Unhandled error in Deferred:
2018-06-25 11:36:51 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'jianshu.middlewares' has no attribute 'RandomUserAgentMiddleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/bc/.virtualenvs/scrapylenv/lib/python3.5/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'jianshu.middlewares' doesn't define any object named 'RandomUserAgentMiddleware'
2018-06-25 11:37:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:37:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:37:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jianshu', 'LOG_LEVEL': 'INFO', 'SPIDER_MODULES': ['jianshu.spiders'], 'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_FILE': 'jianshu.log'}
2018-06-25 11:37:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage']
2018-06-25 11:37:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 11:37:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 11:37:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 11:37:38 [scrapy.core.engine] INFO: Spider opened
2018-06-25 11:37:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 11:38:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:38:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:38:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jianshu', 'LOG_FILE': 'jianshu.log', 'NEWSPIDER_MODULE': 'jianshu.spiders', 'SPIDER_MODULES': ['jianshu.spiders'], 'LOG_LEVEL': 'INFO'}
2018-06-25 11:38:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 11:38:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 11:38:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 11:38:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 11:38:42 [scrapy.core.engine] INFO: Spider opened
2018-06-25 11:38:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 11:41:55 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:41:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:41:55 [scrapy.crawler] INFO: Overridden settings: {'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_FILE': 'jianshu.log', 'BOT_NAME': 'jianshu', 'SPIDER_MODULES': ['jianshu.spiders']}
2018-06-25 11:41:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-06-25 11:41:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 11:41:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 11:41:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 11:41:55 [scrapy.core.engine] INFO: Spider opened
2018-06-25 11:41:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 11:42:25 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:42:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:42:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jianshu', 'LOG_FILE': 'jianshu.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'jianshu.spiders', 'SPIDER_MODULES': ['jianshu.spiders']}
2018-06-25 11:42:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 11:42:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 11:42:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 11:42:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 11:42:25 [scrapy.core.engine] INFO: Spider opened
2018-06-25 11:42:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 11:43:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:43:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:43:30 [scrapy.crawler] INFO: Overridden settings: {'LOG_FILE': 'jianshu.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'jianshu', 'NEWSPIDER_MODULE': 'jianshu.spiders', 'SPIDER_MODULES': ['jianshu.spiders']}
2018-06-25 11:43:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 11:43:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 11:43:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 11:43:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 11:43:30 [scrapy.core.engine] INFO: Spider opened
2018-06-25 11:43:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 11:43:58 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:43:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:43:58 [scrapy.crawler] INFO: Overridden settings: {'SPIDER_MODULES': ['jianshu.spiders'], 'NEWSPIDER_MODULE': 'jianshu.spiders', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'jianshu', 'LOG_FILE': 'jianshu.log'}
2018-06-25 11:43:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 11:43:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 11:43:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 11:43:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 11:43:58 [scrapy.core.engine] INFO: Spider opened
2018-06-25 11:43:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 11:47:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:47:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:47:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jianshu', 'NEWSPIDER_MODULE': 'jianshu.spiders', 'SPIDER_MODULES': ['jianshu.spiders'], 'LOG_LEVEL': 'INFO', 'LOG_FILE': 'jianshu.log'}
2018-06-25 11:47:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-06-25 11:47:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 11:47:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 11:47:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 11:47:31 [scrapy.core.engine] INFO: Spider opened
2018-06-25 11:47:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 11:49:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:49:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:49:40 [scrapy.crawler] INFO: Overridden settings: {'LOG_FILE': 'jianshu.log', 'LOG_LEVEL': 'INFO', 'SPIDER_MODULES': ['jianshu.spiders'], 'NEWSPIDER_MODULE': 'jianshu.spiders', 'BOT_NAME': 'jianshu'}
2018-06-25 11:49:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 11:49:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 11:49:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 11:49:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 11:49:40 [scrapy.core.engine] INFO: Spider opened
2018-06-25 11:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 11:54:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 11:54:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 11:54:56 [scrapy.crawler] INFO: Overridden settings: {'LOG_LEVEL': 'INFO', 'LOG_FILE': 'jianshu.log', 'SPIDER_MODULES': ['jianshu.spiders'], 'BOT_NAME': 'jianshu', 'NEWSPIDER_MODULE': 'jianshu.spiders'}
2018-06-25 11:54:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-06-25 11:54:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 11:54:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 11:54:56 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 11:54:56 [scrapy.core.engine] INFO: Spider opened
2018-06-25 11:54:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-06-25 14:04:59 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: jianshu)
2018-06-25 14:04:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
2018-06-25 14:04:59 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'jianshu.spiders', 'BOT_NAME': 'jianshu', 'SPIDER_MODULES': ['jianshu.spiders'], 'LOG_FILE': 'jianshu.log', 'LOG_LEVEL': 'INFO'}
2018-06-25 14:04:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-06-25 14:04:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-06-25 14:04:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-06-25 14:04:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-06-25 14:04:59 [scrapy.core.engine] INFO: Spider opened
2018-06-25 14:04:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
